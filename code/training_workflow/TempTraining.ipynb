{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0b6846-f212-480a-a70c-1a3107400c53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: Linux-5.19.0-45-generic-x86_64-with-glibc2.35\n",
      "Tensor Flow Version: 2.12.1\n",
      "Keras Version: 2.12.0\n",
      "\n",
      "Python 3.8.19 (default, Apr  6 2024, 17:58:10) \n",
      "[GCC 11.4.0]\n"
     ]
    }
   ],
   "source": [
    "from BiasStudy import datasets, predictionKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e54df51d-3cb4-42f2-8ba5-700db5f2e6b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 20:37:27.216898: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-28 20:37:28.316450: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.layers import Input, Conv2D \n",
    "from tensorflow.keras.layers import MaxPool2D, Flatten, Dense \n",
    "from tensorflow.keras import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f92a2947-30fa-47a7-a20a-12199079eb3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6098879f-e305-4ed1-92f6-0d430e2af49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c159025c-b851-4f67-a0d7-6fdae69aa1f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Under Sampling:  {'light': 28814, 'dark': 24552}\n",
      "After Under sampleing:  {'dark': 100, 'light': 100}\n"
     ]
    }
   ],
   "source": [
    "from BiasStudy.datasets import FairFaceDataset\n",
    "\n",
    "fair_face_dataset = FairFaceDataset(\n",
    "    data_dir = \"/notebooks/data/fairface\",\n",
    "    train_labels_csv_name = \"fairface_label_train.csv\",\n",
    "    validation_labels_csv_name = \"fairface_label_val.csv\",\n",
    "    under_sample = True,\n",
    "    image_shape = (224,224,3),\n",
    "    feature_column = \"file\",\n",
    "    output_col = \"binary_race\",\n",
    "    overwrite_sample_number = 100\n",
    ")\n",
    "\n",
    "train_df = fair_face_dataset.get_train_pd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cad4f01-1aee-4dfa-8a70-c7223611a668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3), activation=\"relu\", input_shape=(224,224,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(2))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b57caa6-8881-4e79-831c-edb9867837b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"conv2d_2\").trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "354ca238-1a80-45cb-af09-19bdedfb2545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "882cfe94-14e0-42fa-a930-2f5111ab98b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 64)        36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 173056)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11075648  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,132,098\n",
      "Trainable params: 11,095,170\n",
      "Non-trainable params: 36,928\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca6e756d-be38-4f74-8fcc-3fdb62bed443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17ada9f4-85bb-47f5-aea4-7b9bbee9a93a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    target_size = (fair_face_dataset.get_image_width(),fair_face_dataset.get_image_height()),\n",
    "    x_col = fair_face_dataset.get_feature_col_name(),\n",
    "    y_col = fair_face_dataset.get_output_col_name(), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = \"categorical\",\n",
    "    subset = \"training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66663ad-eebb-4671-a29c-3473f4661a0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cb60017-16fc-42d0-89f2-19c629f69e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    target_size = (fair_face_dataset.get_image_width(),fair_face_dataset.get_image_height()),\n",
    "    x_col = fair_face_dataset.get_feature_col_name(),\n",
    "    y_col = fair_face_dataset.get_output_col_name(),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = \"categorical\",\n",
    "    subset = \"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f42d4e-4415-4261-ae7a-17041d949e94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b05329-9783-4eda-bc00-cdb0e5e10a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b834bb8-31da-4389-922b-f9d582a8c008",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(\"./outputs/checkpoints\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"./outputs/logging\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"./outputs/model\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"./outputs/weights\").mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2dfea1-63d2-438f-98ba-9f68cd6f2bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath=\"outputs/checkpoints/cp-{epoch:02d}.ckpt\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    monitor = 'val_accuracy',\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad29cfdf-d966-4fcb-b7f4-919ce65fb0cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_csv = CSVLogger(\n",
    "    filename = \"outputs/logging/logs.csv\",\n",
    "    append = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469544a9-09f7-42ca-8075-4868fe3233b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callbacks_list = [checkpoint, log_csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eab18d-d60b-44a1-bec7-36b5a293bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    "    start_from_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b29bf-5cf1-4c4a-b9ac-f5e08e14aade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history.append(\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        epochs = 2,\n",
    "        validation_data = validation_generator,\n",
    "        callbacks=callbacks_list\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2dec6f-986d-43b7-a901-86aec61f3d53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(train_generator)\n",
    "validation_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce6a0c-3cbd-475b-8cad-7c7c5746c6b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"outputs/model/model_name.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c97a9f-4ea5-4408-bcea-78c8196fe486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"./outputs/weights/model_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f95fde84-8b32-45cb-a38a-36b61b95fb89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 20:37:34.069612: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-28 20:37:34.117061: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-28 20:37:34.117394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-28 20:37:34.118977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-28 20:37:34.119235: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-28 20:37:34.119430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-28 20:37:35.224737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-28 20:37:35.224992: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-28 20:37:35.225180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-28 20:37:35.225315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15502 MB memory:  -> device: 0, name: Quadro P5000, pci bus id: 0000:00:05.0, compute capability: 6.1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fair_face_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model2 \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[0;32m----> 2\u001b[0m model2\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m32\u001b[39m,(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m\u001b[43mfair_face_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mget_image_shape()))\n\u001b[1;32m      3\u001b[0m model2\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m      4\u001b[0m model2\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fair_face_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Conv2D(32,(3,3), activation=\"relu\", input_shape=fair_face_dataset.get_image_shape()))\n",
    "model2.add(layers.MaxPooling2D((2,2)))\n",
    "model2.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model2.add(layers.MaxPooling2D((2,2)))\n",
    "model2.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(64, activation=\"relu\"))\n",
    "model2.add(layers.Dense(2))\n",
    "\n",
    "model2.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model2.load_weights(\"./outputs/weights/model_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a513da95-ad5b-4049-b4d3-0cbca85bca69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss, train_acc = model2.evaluate(train_generator)\n",
    "validation_loss, test_acc = model2.evaluate(validation_generator)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872341a8-e024-4408-9f53-904240b22e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model3 = tf.keras.models.load_model(\"load_weights_name.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2922f05-f18f-43f1-83a3-9d7abc9da5a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss, train_acc = model3.evaluate(train_generator)\n",
    "validation_loss, test_acc = model3.evaluate(validation_generator)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39a41f0d-e966-44a6-8e29-0e49087f7670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def load_config_and_validate(path: str) -> dict:\n",
    "    with open(path, 'r') as stream:\n",
    "        config = yaml.safe_load(stream)\n",
    "    \n",
    "    if \"model\" not in config:\n",
    "        raise Exception(\"Missing field 'model'\")\n",
    "        \n",
    "    if \"model_name\" not in config[\"model\"]:\n",
    "        raise Exception(\"Missing field 'model.model_name'\")\n",
    "        \n",
    "    if \"conv_blocks\" not in config[\"model\"]:\n",
    "        raise Exception(\"Missing field 'model.conv_blocks'\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "config_dict = load_config_and_validate(\"./sample.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6963d86e-59e1-4b2d-a984-9f3bf26119e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82c199f1-ad27-41d1-8960-b73f6caf1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def create_model(\n",
    "    num_classes: int,\n",
    "    config_dict: dict,\n",
    "    image_shape: Tuple[int, int, int] = (224,224,3)\n",
    "):\n",
    "    model_name = config_dict['model']['model_name']\n",
    "    cnn_model = keras.Sequential(name=model_name)\n",
    "    cnn_model.add(Input(shape=image_shape))\n",
    "    input = Input(shape = image_shape)\n",
    "    for block_num, (block_key, block_config) in enumerate(config_dict['model']['conv_blocks'].items()):\n",
    "        for conv_layer_num in range(0, block_config['num_conv_layers']):\n",
    "            cnn_model.add(\n",
    "                Conv2D(\n",
    "                    filters = block_config['num_filters'],\n",
    "                    kernel_size = block_config['kernel_size'],\n",
    "                    padding = 'same',\n",
    "                    activation = 'relu',\n",
    "                    name = \"block{}_conv{}\".format(block_num, conv_layer_num)\n",
    "                )\n",
    "            )\n",
    "        cnn_model.add(MaxPool2D(pool_size =2, strides =2, padding ='same', name=\"block{}_pool\".format(block_num)))\n",
    "    cnn_model.add(Flatten(name = \"flatten\"))\n",
    "    \n",
    "    if \"flatt_layers\" in config_dict['model']:\n",
    "        for flat_layer_num, (flat_key, flat_config) in enumerate(config_dict['model']['flatt_layers'].items()):\n",
    "            cnn_model.add(Dense(units = flat_config['num_units'], activation ='relu'))\n",
    "\n",
    "    cnn_model.add(Dense(units = num_classes, activation ='softmax', name = \"prediction\"))\n",
    "    return cnn_model\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a74103d0-b187-4235-b18f-75b4426ba2c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "\n",
    "def compile_model(num_classes: int, cnn_model: keras.Model):\n",
    "    loss = None\n",
    "    if num_classes > 1:\n",
    "        loss = \"categorical_crossentropy\"\n",
    "    else:\n",
    "        loss = \"mean_squared_error\"\n",
    "    cnn_model.compile(\n",
    "        optimizer = Adam(learning_rate=0.001),\n",
    "        loss = loss,\n",
    "        metrics = ['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22915e06-9760-49af-b058-0062330a8e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/72746245\n",
    "class EpochModelCheckpoint(tf.keras.callbacks.ModelCheckpoint):\n",
    "\n",
    "    def __init__(self,\n",
    "                 filepath,\n",
    "                 frequency=1,\n",
    "                 monitor='val_loss',\n",
    "                 verbose=0,\n",
    "                 save_best_only=False,\n",
    "                 save_weights_only=False,\n",
    "                 mode='auto',\n",
    "                 options=None,\n",
    "                 **kwargs):\n",
    "        super(EpochModelCheckpoint, self).__init__(filepath, monitor, verbose, save_best_only, save_weights_only,\n",
    "                                                   mode, \"epoch\", options)\n",
    "        self.epochs_since_last_save = 0\n",
    "        self.frequency = frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epochs_since_last_save += 1\n",
    "        # pylint: disable=protected-access\n",
    "        if self.epochs_since_last_save % self.frequency == 0:\n",
    "            self._save_model(epoch=epoch, batch=None, logs=logs)\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a13767c0-6eeb-40b1-8ff5-682d02e6c6bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def create_dirs(model_name: str):\n",
    "    checkpoint_dir = \"./outputs/{}/checkpoints/\".format(model_name)\n",
    "    Path(checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    logging_dir = \"./outputs/{}/logging/\".format(model_name)\n",
    "    Path(logging_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    model_dir = \"./outputs/{}/model/\".format(model_name)\n",
    "    Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    weight_dir = \"./outputs/{}/weights/\".format(model_name)\n",
    "    Path(weight_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    return checkpoint_dir, logging_dir, model_dir, weight_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db59c8a1-6d0f-43a7-b3e3-7922d066ba56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from keras.preprocessing.image import DataFrameIterator\n",
    "\n",
    "def train_model(\n",
    "    early_stopping_patience: int,\n",
    "    cnn_model: keras.Model,\n",
    "    train_generator: DataFrameIterator,\n",
    "    validation_generator: DataFrameIterator,\n",
    "    num_epochs: int,\n",
    "    checkpoint_frequencey: int = 1,\n",
    "):\n",
    "    checkpoint_dir, logging_dir, model_dir, weight_dir = create_dirs(cnn_model.name)\n",
    "    \n",
    "    checkpoint_file_path = checkpoint_dir + \"cp-{epoch:02d}.ckpt\"\n",
    "    checkpoint_callback = EpochModelCheckpoint(\n",
    "        filepath = checkpoint_file_path,\n",
    "        monitor = 'val_accuracy',\n",
    "        frequencey = checkpoint_frequencey,\n",
    "        verbose = 1\n",
    "    )\n",
    "    \n",
    "    log_csv_file_path = logging_dir + \"logs.csv\"\n",
    "    log_csv_callback = CSVLogger(\n",
    "        filename = log_csv_file_path,\n",
    "        append = True\n",
    "    )\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=early_stopping_patience, \n",
    "        mode='min',\n",
    "        min_delta=0.0001\n",
    "    )\n",
    "\n",
    "    callbacks_list = [checkpoint_callback, log_csv_callback, early_stopping]\n",
    "    \n",
    "    cnn_model.fit(\n",
    "        train_generator,\n",
    "        epochs = num_epochs,\n",
    "        validation_data = validation_generator,\n",
    "        callbacks = callbacks_list\n",
    "    )\n",
    "    \n",
    "    train_loss, train_acc = cnn_model.evaluate(train_generator)\n",
    "    validation_loss, test_acc = cnn_model.evaluate(validation_generator)\n",
    "    print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "    \n",
    "    cnn_model.save(model_dir + \"model.h5\".format(cnn_model.name))\n",
    "    cnn_model.save_weights(weight_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff41d7f3-ac58-496c-b3dd-ec21864250de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f482da0e-aa8e-46be-ae89-4a8f71ce4de3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn = create_model(num_classes = 2, config_dict = config_dict)\n",
    "compile_model(num_classes = 2, cnn_model = cnn)\n",
    "# cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55ffc4ac-bea0-4c44-b34a-33547ba47dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.2288 - accuracy: 0.6187\n",
      "Epoch 1: saving model to ./outputs/model_8conv_3kernel/checkpoints/cp-01.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./outputs/model_8conv_3kernel/checkpoints/cp-01.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./outputs/model_8conv_3kernel/checkpoints/cp-01.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 2s/step - loss: 2.2288 - accuracy: 0.6187 - val_loss: 0.3462 - val_accuracy: 1.0000\n",
      "Epoch 2/4\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9388 - accuracy: 0.5437\n",
      "Epoch 2: saving model to ./outputs/model_8conv_3kernel/checkpoints/cp-02.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./outputs/model_8conv_3kernel/checkpoints/cp-02.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./outputs/model_8conv_3kernel/checkpoints/cp-02.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 902ms/step - loss: 0.9388 - accuracy: 0.5437 - val_loss: 1.1497 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/4\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7151 - accuracy: 0.6333\n",
      "Epoch 3: saving model to ./outputs/model_8conv_3kernel/checkpoints/cp-03.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./outputs/model_8conv_3kernel/checkpoints/cp-03.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./outputs/model_8conv_3kernel/checkpoints/cp-03.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 734ms/step - loss: 0.7116 - accuracy: 0.6375 - val_loss: 0.4889 - val_accuracy: 0.9500\n",
      "Epoch 4/4\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6299 - accuracy: 0.6250\n",
      "Epoch 4: saving model to ./outputs/model_8conv_3kernel/checkpoints/cp-04.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./outputs/model_8conv_3kernel/checkpoints/cp-04.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./outputs/model_8conv_3kernel/checkpoints/cp-04.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 775ms/step - loss: 0.6299 - accuracy: 0.6250 - val_loss: 0.6151 - val_accuracy: 0.8500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.6831 - accuracy: 0.5500\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6151 - accuracy: 0.8500\n",
      "Train: 0.550, Test: 0.850\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    cnn_model = cnn,\n",
    "    train_generator = train_generator,\n",
    "    validation_generator = validation_generator,\n",
    "    num_epochs = 4,\n",
    "    early_stopping_patience = 3,\n",
    "    checkpoint_frequencey = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9bc477-e909-48a9-bcc9-a5d2ff07d38f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# class History_trained_model(object):\n",
    "#     def __init__(self, history, epoch, params):\n",
    "#         self.history = history\n",
    "#         self.epoch = epoch\n",
    "#         self.params = params\n",
    "\n",
    "# def save_history():\n",
    "#     with open(savemodel_path+'/history', 'wb') as file:\n",
    "#     model_history= History_trained_model(history.history, history.epoch, history.params)\n",
    "#     pickle.dump(model_history, file, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# def load_history():\n",
    "#     with open(savemodel_path+'/history', 'rb') as file:\n",
    "#         history=pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
